// [[Rcpp::depends(RcppEigen)]]
#include <RcppEigen.h>

#include <iostream>

#include "train.h"
#include "Predict.h"
#include "Spectrum.h"

using namespace Rcpp;
using namespace Eigen;

static const Eigen::VectorXd N_init = Eigen::VectorXd();


//' Fit Gaussian process logistic regression with local anchor embedding kernels
//'
//' @param X Training sample, a (m, d) matrix, each row indicates one point in R^d.
//' @param Y A numeric vector with length(m), count of the positive class.
//' @param X_new Testing sample, a (n-m, d) matrix, each row indicates one point in R^d.
//' @param s An integer indicating the number of the subsampling.
//' @param r An integer, the number of the nearest neighbor points.
//' @param K An integer, the number of used eigenpairs to construct heat kernel,
//' the defaulting value is `NULL`, that is, `K=min(n,s)`.
//' @param N A numeric vector with length(m), total count.
//' @param sigma A non-negative number, the weight coefficient of ridge penalty on H,
//' the defaulting value is 1e-3.
//' @param approach A character vector, taking value in c("posterior", "marginal"),
//' decides which objective function to be optimized, defaulting value is `posterior`.
//' @param cl The cluster to make parallel computing,
//' typically generated by `parallel::makeCluster(num_workers)`.
//' The defaulting value of cl is NULL, that is, sequential computing.
//' @param models A list with four components
//' \describe{
//' \item{subsample}{the method of subsampling, the defaulting value is `kmeans`.}
//' \item{kernel}{the type of kernel to compute cross similarity matrix W, the
//' defaulting value is `lae`.}
//' \item{gl}{the kind of graph Laplacian L, the defaulting value is `rw`.}
//' \item{root}{whether to square root eigenvalues of the two steps similarity matrix W,
//' the defaulting value is `FALSE`.}
//' }
//' @param output_cov Bool, whether to output covariance, defaulting value is `FALSE`.
//'
//' @return `Y_pred` A numeric vector with length(m_new), each element indicates
//' the label in the corresponding new sample point.
//' @export
//'
//' @examples
//' X0 <- matrix(rnorm(3*3), 3, 3)
//' X1 <- matrix(rnorm(3*3, 5), 3, 3)
//' Y <- c(1,1,1,0,0,0)
//' X <- rbind(X0,X1)
//' X0_new <- matrix(rnorm(10*3),10,3)
//' X1_new <- matrix(rnorm(10*3, 5),10,3)
//' X_new <- rbind(X0_new, X1_new)
//' Y_new <- c(rep(1,10),rep(0,10))
//' s <- 6; r <- 3
//' K <- 5
//' Y_pred <- fit_lae_logit_gp_cpp(X, Y, X_new, s, r, K)
// [[Rcpp::export(fit_lae_logit_gp_cpp)]]
Rcpp::List fit_lae_logit_gp_cpp(Eigen::MatrixXd X, Eigen::VectorXd Y, Eigen::MatrixXd X_new,
                                int s, int r, int K, Eigen::VectorXd N,
                                double sigma, std::string approach,
                                Rcpp::List models,
                                bool output_cov) {
  std::cout << "Local anchor embedding:" << std::endl;

  int m = X.rows(); int m_new = X_new.rows();
  int n = m + m_new;

  if(K<0) {
    K = s;
  }

  if(N.size()==0) {
    N = Eigen::VectorXd::Ones(m);
  }

  EigenPair eigenpair = heat_kernel_spectrum_cpp(X, X_new, s, r, K, models);

  Eigen::VectorXi idx = Eigen::VectorXi::LinSpaced(m, 0, m-1);

  // train model
  std::cout << "Training..." << std::endl;
  // empirical Bayes to optimize t
  ReturnValue res;
  if(approach=="posterior") {
    PostOFData postdata(eigenpair, Y, N, idx, K, sigma);
    res = train_lae_logit_gp_cpp(&postdata, approach);
  } else if(approach=="marginal") {
    MargOFData margdata(eigenpair, Y, N, idx, K, sigma);
    res = train_lae_logit_gp_cpp(&margdata, approach);
  } else {
    Rcpp::stop("This model selection approach is not supported!");
  }


  std::cout << "By " << approach << " method, optimal t = " << res.t \
              << ", the objective function is " << res.obj << std::endl;

  // test model
  std::cout << "Testing..." << std::endl;
  // construct covariance matrix
  Eigen::VectorXi idx0 = Eigen::VectorXi::LinSpaced(m, 0, m-1);
  Eigen::VectorXi idx1 = Eigen::VectorXi::LinSpaced(m_new, m, n-1);
  Eigen::MatrixXd Cvv = HK_from_spectrum_cpp(eigenpair, K, res.t, idx0, idx0);
  Cvv.diagonal().array() += sigma;
  Eigen::MatrixXd Cnv = HK_from_spectrum_cpp(eigenpair, K, res.t, idx1, idx0);

  // predict labels on new samples
  Eigen::VectorXd Y_pred = Rcpp::as<Eigen::VectorXd>(test_pgbinary_cpp(Cvv, Y, Cnv)["Y_pred"]);
  std::cout << "Testing over" << std::endl;

  if(output_cov) {
    Eigen::MatrixXd C(n,m);
    C.topRows(m) = Cvv;
    C.bottomRows(m_new) = Cnv;
    return Rcpp::List::create(Named("Y_pred")="Y_pred", Named("C")=C);
  } else {
    return Rcpp::List::create(Named("Y_pred")="Y_pred");
  }
}
